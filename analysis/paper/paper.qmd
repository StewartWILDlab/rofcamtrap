---
title: "Using Camera Traps and Computer Vision to Quantify Wildlife Diversity and Co-Occurrence across Ontario’s Far North"
author:
  - Valentin Lucet:
      # correspondence: "yes"
      email: valentin.lucet@gmail.com
      orcid: "0000-0003-0268-818X"
      institute: wlu
  - Frances Stewart:
      institute: wlu
      orcid: "0000-0001-9344-8346"
institute:
  - wlu:
      name: Wilfrid Laurier University
      # address: 23 Science Street, Eureka, Mississippi, USA
title-block-published: "Last updated"  
date: now
date-format: long
format: 
  docx:
    reference-doc: "../templates/template_modified.docx" # Insert path for the DOCX file
execute:
  echo: true
  warning: false
  message: false
  comment: "#>"
  fig-path: "../figures/"
  fig-dpi: 600
filters:
  - ../templates/scholarly-metadata.lua
  - ../templates/author-info-blocks.lua
  - ../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/landscape-ecology.csl" # Insert path for the bib-style
abstract: |
  Northern Ontario holds some of the world’s last intact wild places, but it is under pressure from resource extraction and climate change. Our understanding of biodiversity measures like species occurrence, abundance, diversity, and density for the region are lacking, yet needed for strategic decision-making about the impacts of resource extraction on ecosystem services and biodiversity. The use of non-invasive survey methods, such as camera trap arrays, has significantly changed our ability to quantify wildlife across large and remote regions. However, these methods generate a large amount of data and require tools to speed up the identification of species. Machine learning methods, such as deep neural networks, are a promising tool to overcome this data bottle-neck. Yet, variables like strong seasonality, changes in vegetation type, and species characteristics can strongly impact their efficacy. The extent to which these methods perform for northern regions is not well established. Using an array of cameras deployed in an heterogeneous sampling area straddling two of Northern Ontario’s ecozones (Hudson Bay Lowlands and Ontario Shield), we first look to quantify current species diversity and co-occurrence. We've recently developed an open-source workflow for camera trap image identification, access, and storage, which we are using to identify images, with next steps involving the development of an image classifier.

# keywords: |
#   keyword 1; keyword 2; keyword 3
# highlights: |
#   These are the highlights. 
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '~/Documents/WILDLab/rofcamtrap/')
options(scipen = 1, digits = 2)
library(magrittr)
```

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored.

With the following code you can access and display values from the yml header above.
Keywords: `r rmarkdown::metadata$keywords`
Highlights: `r rmarkdown::metadata$highlights`

Here is a citation [@Marwick2017] -->

<!-- The actual document text starts here:

## Summary

TBW

\newpage -->

## Introduction

The James Bay Lowlands in Northern Ontario hold some of the world’s last intact wild places but it is under pressure from resource extraction and global warming. Our understanding of basic biodiversity measures like species occurrence, abundance, diversity, and density for the region are still rudimental but needed to weigh ecological-economical decision tradeoffs.   
Traditionally, quantifying and monitoring biodiversity in northern regions required expensive and time-consuming field surveys. But today, the use of non-intrusive methods, such as arrays of 100s of camera traps, has significantly changed field practices for reliably quantifying wildlife across large and remote regions. However, these methods generate a large amount of data and require tools to speed up the identification, and processing, of image datasets.

Machine learning methods, such as deep neural networks, are now in use to automate the process of species identification and help in that endeavour. We aim to evaluate the viability of deep neural networks for camera trap surveys currently taking place in Northern Ontario’s heterogeneous landscapes, including the Hudson Bay Lowlands and Ontario Shield ecozones, as variables like weather, seasonality, vegetation type, and species characteristics can impact the performance of these methods. There are currently no available machine learning models for identifying species from images in northern regions and developing one would be beneficial as a monitoring and modeling tool for northern boreal ecosystems.

The extent to which these methods perform for northern regions is not well established. Using an array of cameras deployed in an heterogeneous sampling area straddling two of Northern Ontario’s ecozones (Hudson Bay Lowlands and Ontario Shield), we first look to quantify current species diversity and co-occurrence. We've recently developed an open-source workflow for camera trap image identification, access, and storage, which we are using to identify images, with next steps involving the development of an image classifier.

## Methods

### Camera deployment

The camera deployment protocol follows a spatially balanced hierarchical design that provides an even distribution of sample sites across biotic and abiotic conditions within the study area. The study sites span three ecoregions and two ecozones. The network was established by CWS in 2020 and seasonally equipped in a rolling design with 500 autonomous recording units (ARUs) to monitor audible species diversity paired with site-specific on-ground vegetation imagery. In 2022, 232 unbaited wildlife camera traps (CTs) were added to a subset of study sites to quantify mammalian occurrence and diversity. @fig-deployment shows the location of the and their current status. retrieved cameras were retrieved in September 2022.

```{r}
#| label: spatial-basics
#| echo: false

RoF_CameraDeploymentLog_WLU <- 
  readxl::read_excel(paste0("analysis/data/raw_data/camera_deployments/",
                            "WLU_Cameras_Log_2023.xlsx")) %>% 
  janitor::clean_names()

cams_sf <- RoF_CameraDeploymentLog_WLU %>% 
  dplyr::filter(!is.na(latitude)) %>% 
  dplyr::filter(!is.na(longitude)) %>% 
  sf::st_as_sf(coords=c("longitude","latitude"), crs="EPSG:4326") %>% 
  dplyr::mutate(is_retrieved = ifelse(!is.na(date_retrieved), "Yes", "No"))

coords <- cams_sf %>% 
  sf::st_coordinates() %>% 
  as.data.frame()

cams_sf_coords <- dplyr::bind_cols(cams_sf, coords)

zones <- 
  sf::st_read("analysis/data/raw_data/ecozones/ECOREGN/LIO-2022-10-25/ECOREGION.shp",
              quiet=TRUE, ) %>% 
  sf::st_transform(crs = sf::st_crs(cams_sf))

zones_filter <- zones %>%
  sf::st_filter(cams_sf)

pols <- sf::st_coordinates(zones_filter) %>% 
  as.data.frame()

regions_labels <- zones_filter %>% 
  sf::st_drop_geometry() %>% 
  dplyr::bind_cols(data.frame(x = c(-88.5, -84, -88.5),
                              y = c(55, 52, 52.6)))

map <- ggmap::get_stamenmap( bbox = c(left = -90, bottom = 50, right = -83, top = 56), 
                             zoom = 9, maptype = "terrain-background")
```

```{r}
#| label: fig-deployment
#| echo: false
#| fig-cap: "Camera deployment status"

base <- ggmap::ggmap(map) +
  ggplot2::labs(x = "Longitude", y = "Latitude") +
  # ggplot2::geom_polygon(data = pols, ggplot2::aes(x=X, y=Y), col = 1, fill = NA)
  ggplot2::geom_path(data = pols, ggplot2::aes(x=X, y=Y), col = 1, linewidth=0.2)

p <- base +
  ggplot2::geom_label(ggplot2::aes(x=x, y=y, label=ECOREGION),inherit.aes = FALSE,
                      size = 2.5, data = regions_labels) +
  ggplot2::geom_point(data = cams_sf_coords, cex = 1, shape=21, col="black",
                      ggplot2::aes(x=X, y=Y, fill=is_retrieved), 
                      inherit.aes = FALSE) +
  ggplot2::labs(fill = "Camera \nRetrieved")
p
```

### Image detection

```{r}
#| label: load-data
#| echo: false

if (!file.exists("analysis/data/derived_data/annotations.rds") |
    !file.exists("analysis/data/derived_data/annotations_wide.rds")){
  source("scripts/1_preprocess_annotations.R")
} else {
  anns <- readRDS("analysis/data/derived_data/annotations.rds")
  anns_wide <- readRDS("analysis/data/derived_data/annotations_wide.rds")
}

if (!file.exists("analysis/data/derived_data/detections.rds")){
  source("scripts/2_preprocess_detections.R")
} else {
  dets <- readRDS("analysis/data/derived_data/detections.rds")
}

# Compute total amount of images
nb_image <- length(unique(dets$image_id))
nb_image_fmt <- prettyNum(nb_image, big.mark = ",")

# Hardcoded check
stopifnot(nb_image == 2788375)

exif <- readr::read_csv("analysis/data/raw_data/exif/exif_combined.csv") %>% 
  dplyr::select(-SourceFile) %>% 
  dplyr::mutate(image_id = stringr::str_replace_all(source_file, "/", "_")) %>% 
  dplyr::mutate(image_id = stringr::str_replace_all(image_id, ".JPG", "")) %>% 
  dplyr::mutate(image_id = stringr::str_sub(image_id, 6)) %>% 
  janitor::clean_names()
```

Images were retrieved from all cameras using a SD card reader and copied onto a 10 TB hard drive of brand LaCie. The images amounted to 1.8TB of memory on disk, for a total of __`r nb_image_fmt`__ images. Images were stored with the following directory structure:

- Plot id (e.g. P128)
- Site id (e.g. P128-1)
- Camera id (e.g. CFS-10)
- DCIM folder (created by the camera)
- Overflow folder (e.g. 100RECNX, each such folder contains up to 10,000 images)

The images were processed through the animal detection model MegaDetector, version 5.0, using a Lenovo X1 laptop with a NVIDIA GeForce GTX 1650 Max-Q graphics card, which took about 2 weeks of quasi-continuous processing to complete. The model processes each image and produces “detections” (bounding boxes) at a  variable confidence score.

```{r}
#| label: basics-stats-1
#| echo: false

# Select and distinct down to image-based infos
dets_images <- dets %>%  dplyr::select(image_id, max_confidence, isempty) %>% 
  dplyr::distinct()

# Breakdown of which images triggered a MD detection
dets_tb <- dets_images$isempty %>% table()
dets_tb_sum <- sum(dets_tb)
dets_tb_percent <- dets_tb/dets_tb_sum*100

dets_tb_fmt <- prettyNum(dets_tb, big.mark = ",")

# Check total number of images
stopifnot(dets_tb_sum == length(unique(dets$image_id)))
```

About __`r dets_tb_percent[1]` %__ of the images, or __`r dets_tb_fmt[1]`__ images, were found by the model to possibly have either a person, animal, or vehicle. The model did not produce detections for __`r dets_tb_fmt[2]`__ images, or __`r dets_tb_percent[2]` %__ of the total.

```{r}
#| label: basics-stats-2
#| echo: false
dets_0 <- dets %>% dplyr::filter(confidence > 0)
dets_0.1 <- dets %>% dplyr::filter(confidence > 0.1)

# Breakdown of detections by categories (animal, person, vehicles)
dets_tb_cat_unfil <- dets_0 %>% dplyr::pull(category_id) %>% table()
dets_tb_cat_unfil_sum <- sum(dets_tb_cat_unfil)
dets_tb_cat_unfil_percent <- dets_tb_cat_unfil/dets_tb_cat_unfil_sum*100

dets_tb_cat_unfil_fmt <- prettyNum(dets_tb_cat_unfil, big.mark = ",")
dets_tb_cat_unfil_sum_fmt <- prettyNum(dets_tb_cat_unfil_sum, big.mark = ",")

# Breakdown of detections above 0.1 by categories (animal, persons, vehicles)
dets_tb_cat <- dets_0.1 %>% dplyr::pull(category_id) %>% table()
dets_tb_cat_sum <- sum(dets_tb_cat)
dets_tb_cat_percent <- dets_tb_cat/sum(dets_tb_cat)*100

dets_tb_cat_fmt <- prettyNum(dets_tb_cat, big.mark = ",")
dets_tb_cat_sum_fmt <- prettyNum(dets_tb_cat_sum, big.mark = ",")
```

This resulted in a total of __`r dets_tb_cat_unfil_sum_fmt`__ detections. The totals for each category are: __`r dets_tb_cat_unfil_fmt[1]`__ animals (or __`r dets_tb_cat_unfil_percent[1]` %__); __`r dets_tb_cat_unfil_fmt[2]`__ persons (or __`r dets_tb_cat_unfil_percent[2]` %__); and __`r dets_tb_cat_unfil_fmt[3]`__ vehicles (or __`r dets_tb_cat_unfil_percent[3]` %__).

Using a cut-off value for confidence threshold of 0.1, this left us with a total of __`r dets_tb_cat_sum_fmt`__ detections to sort through (see @fig-detections-histogram for an histogram of the detection scores, grouped by detection types). The totals for each category are: __`r dets_tb_cat_fmt[1]`__ animals (or __`r dets_tb_cat_percent[1]` %__); __`r dets_tb_cat_fmt[2]`__ persons (or __`r dets_tb_cat_percent[2]` %__); and __`r dets_tb_cat_fmt[3]`__ vehicles (or __`r dets_tb_cat_percent[3]` %__). 

```{r}
#| label: fig-detections-histogram
#| echo: false
#| fig-cap: "Histogram of detection confidence scores."

# Histogram of confidence scores above 0.1
dets_0.1 %>% 
  dplyr::mutate(category_id = as.character(category_id)) %>% 
  dplyr::mutate(Type = dplyr::case_match(category_id,
                                         "0" ~ "Empty",
                                         "1" ~ "Animal",
                                         "2" ~ "Person",
                                         "3" ~ "Vehicle")) %>% 
  ggplot2::ggplot() +
  ggplot2::theme_bw() +
  ggplot2::geom_histogram(ggplot2::aes(x=confidence, group=Type, fill=Type),
                          bins = 100) +
  ggplot2::scale_fill_viridis_d() +
  ggplot2::xlab("Confidence Score") +
  ggplot2::ylab("Count")
```

Finally, it is important to note that not only pictures with detections were uploaded to the platform. Because camera traps produce images in bursts, we included all the pictures from a given bursts if any of the images in the bursts include a detection with certainty above the threshold.

### Tagging platform selection

We had in mind the following criteria when selecting the proper tool to tag our images and bounding boxes:

- *Deployable online*. This was to allow for for multiple taggers
- *Flexible tagging interface*. Few platforms allow for a full customization of the tagging interface, down to the smallest details.
- *Allowing to tag multiple bounding boxes per image*. Most platforms only allow for tagging the entire image, and not for portions of it (e.g. bounding boxes of detections produced by MegaDetector). This is necessary for when we will crop our images to train our neural network model. 
- *Optionally, open source,* to allow for maximum reproducibility of the process. 

We looked at platforms not traditionally used for tagging camera trap images, but used by the larger community of machine learning practitioners for which the task of tagging is a common step, known as labeling. We found two platforms that matched all those criteria: LabelStudio and CVAT. After testing both platforms, LabelStudio was chosen as it was simpler to implement. The Community edition of LabelStudio was deployed on an Ubuntu virtual machine hosted by Compute Canada, using an Apache server and a NGINX reverse proxy, which is a standard approach for custom hosting of websites.

### Tagging progress

```{r}
#| label: basics-stats-3
#| echo: false

# Number of uploaded images
uploaded <- dets %>% dplyr::filter(confidence > 0.1) %>% dplyr::pull(image_id) %>% 
  unique() %>% length()

uploaded_fmt <- prettyNum(uploaded, big.mark = ",")

# Number of images viewed
viewed <- length(unique(anns_wide$image_id))
viewed_fmt <- prettyNum(viewed, big.mark = ",")

# Percentage of image viewed (in the total)
viewed_pct <- viewed/length(unique(dets$image_id))*100

# Percentage of image viewed from what was uploaded to the platform
viewed_pct_up <- length(unique(anns_wide$image_id))/uploaded*100

# Filter for non empty images
anns_wide_noempty <- anns_wide %>%
  dplyr::filter(!is.na(to_name))

# Number of processed annotations
processed <- nrow(anns_wide_noempty)
processed_fmt <- prettyNum(processed, big.mark = ",")

# Percentage of animal annotations processed
processed_pct <- processed/dets_tb_cat[1]*100

# Number of nonempty images viewed
processed_img <- length(unique(anns_wide_noempty$image_id))
processed_img_fmt <- prettyNum(processed_img, big.mark = ",")

# Percentage of nonempty images viewed (in the total)
processed_img_pct <- processed_img/length(unique(dets$image_id))*100

# Percentage of nonempty images viewed (in the detected images > 0.1)
processed_img_up_pct <- processed_img/uploaded*100
```

Out of the __`r dets_tb_cat_fmt[1]`__ animal detections, __`r processed_fmt`__ have been processed on the platform (or __`r processed_pct` %__) for a total of __`r processed_img_fmt`__ images (i.e. __`r processed_img_pct` %__ of the total amount of images, or __`r processed_img_up_pct` %__ of the total amount of images uploaded to the platform). This does not include the empty images also viewed as part of a set, bringing that amount to 92,826 “detections” and __`r viewed_fmt`__, (i.e. __`r viewed_pct` %__ of the total amount of images, or __`r viewed_pct_up` %__ of the total amount of images uploaded to the platform).

```{r}
#| label: mans
#| echo: false

# Deleted predictions
dels <- anns_wide_noempty %>% dplyr::filter(is.na(species))
dels_nb <- nrow(dels)
dels_nb_fmt <- prettyNum(dels_nb, big.mark = ",")
dels_nb_pct <- dels_nb/nrow(anns_wide_noempty)*100

# Should be no manuals here
stopifnot((anns_wide_noempty %>% dplyr::filter(is.na(species)) 
           %>% dplyr::filter(manual)) == 0)

# Actual annotations
true_anns <- anns_wide_noempty %>% dplyr::filter(!is.na(species))
true_anns_nb <- nrow(true_anns)
# true_anns_nb_fmt <- prettyNum(true_anns_nb, big.mark = ",")
# true_anns_nb_pct <- true_anns_nb/processed*100

# Non manuals 
non_mans <- anns_wide_noempty %>% dplyr::filter(!is.na(species)) %>% 
  dplyr::filter(!manual)
non_mans_nb <- nrow(non_mans)
non_mans_nb_fmt <- prettyNum(non_mans_nb, big.mark = ",")
non_mans_nb_pct <- non_mans_nb/nrow(anns_wide_noempty)*100

# Mans
mans <- anns_wide_noempty %>% dplyr::filter(!is.na(species)) %>% 
  dplyr::filter(manual)
mans_nb <- nrow(mans)
mans_nb_fmt <- prettyNum(mans_nb, big.mark = ",")
mans_nb_pct <- mans_nb/nrow(anns_wide_noempty)*100

# adjusted
orig_tb <- anns_wide_noempty$origin %>% table()
orig_tb_pct <- orig_tb/sum(orig_tb)*100
orig_tb_fmt <- prettyNum(orig_tb, big.mark = ",")
```

Out of the __`r processed_fmt`__ detections, __`r dels_nb_fmt`__ were false positives (or __`r dels_nb_pct` %__), and __`r non_mans_nb_fmt`__ were true positives (or __`r non_mans_nb_pct` %__), to which __`r mans_nb_fmt`__ false negatives were added (manually added bounding boxes, __`r mans_nb_pct` %__). Out of the __`r non_mans_nb_fmt`__ true positives, __`r orig_tb_fmt[3]`__ had to have their bounding box adjusted,

### Issues encountered

The main issue we encountered was a problem in the performances of MegaDetector which caused a lot of false positives, as the model was often tricked by vegetation.

### Analysis

```{r}
#| label: quality-control
#| echo: false

# Only annotations for animals
anns_wide_animals <- anns_wide_noempty %>% 
  dplyr::filter(species != 'Human') %>% 
  dplyr::filter(species != 'Vehicle') %>% 
  dplyr::mutate(camera_id = id %>% stringr::str_split("_") %>% 
                  purrr::map(~.x[[2]]) %>% unlist()) 

# Unknowns and bird breakdown
# anns_wide_animals %>% dplyr::filter(species == "Unknown") %>% 
#   dplyr::pull(id) %>% 
#   stringr::str_sub(1,4) %>% table() %>% sort() 
# anns_wide_animals %>% dplyr::filter(stringr::str_detect(species,"Bird")) %>% 
#   dplyr::pull(id) %>% 
#   stringr::str_sub(1,4) %>% table() %>% sort()

# Joins

anns_wide_animals_joined <- anns_wide_animals %>% 
  dplyr::left_join(exif, by = c("source_file", "image_id"))

anns_wide_animals_joined_mut <- anns_wide_animals_joined %>% 
  dplyr::filter(species != "Unknown") %>%
  dplyr::mutate(plot_id = stringr::str_sub(id, 1, 4)) %>% 
  dplyr::mutate(date_time = lubridate::ymd_hms(exif_date_time_original,
                                               tz = "Canada/Eastern"),
                year = lubridate::year(date_time),
                month = lubridate::month(date_time, label = TRUE),
                day = lubridate::day(date_time),
                ymd = paste(year, month, day, sep = "_"))

# anns_wide_animals_joined_dets <- anns_wide_animals %>% 
#   dplyr::right_join(dets_images, by = "image_id")
```

#### Event definition

- days

#### Ordination and clustering

- two types of ordination: pa and events
- two clustering: basics and geo

## Preliminary results

### Species ID summary

- Most common species

```{r}
#| label: species
#| echo: false

# Summary by speciesanns_wide_noempty$origin %>% table()

anns_wide_animals_table <- anns_wide_animals %>% 
  dplyr::select(camera_id, species) %>% 
  dplyr::filter(species != "Unknown") %>%
  table() %>% 
  `>`(0) %>% 
  `+`(0) %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("camera_id") %>% 
  dplyr::arrange(camera_id)
anns_wide_animals_table_tb <- anns_wide_animals_table %>% 
  dplyr::select(-camera_id)
rownames(anns_wide_animals_table_tb) <- anns_wide_animals_table$camera_id
```

### Ordination

TBW

```{r}
#| label: extract
#| echo: false

lu_16 <- raster::raster("analysis/data/raw_data/land_use/Class/FarNorth_LandCover_Class_UTM16.tif")
lu_17 <- raster::raster("analysis/data/raw_data/land_use/Class/FarNorth_LandCover_Class_UTM17.tif")

lu_dat <- readr::read_csv("analysis/data/raw_data/land_use/attr_table_northen_ont_lc.txt") %>% 
  dplyr::mutate(cats = as.factor(code))

cams_sf_buffers_16 <- cams_sf %>% 
  sf::st_transform(sf::st_crs(lu_16)) %>% 
  sf::st_buffer(dist = 1000)

cams_sf_buffers_17 <- cams_sf %>% 
  sf::st_transform(sf::st_crs(lu_17)) %>% 
  sf::st_buffer(dist = 1000)

extr_16 <- exactextractr::exact_extract(lu_16, cams_sf_buffers_16,
                                        progress = FALSE)
extr_17 <- exactextractr::exact_extract(lu_17, cams_sf_buffers_17,
                                        progress = FALSE)

ind_16 <- which(lapply(extr_16, function(x) all(is.na(x[,1]))) %>% unlist())
ind_17 <- which(lapply(extr_17, function(x) all(is.na(x[,1]))) %>% unlist())

stopifnot(length(unique(c(ind_16, ind_17))) == length(extr_16))

extr_16[ind_16] <- extr_17[ind_16]

extr <- extr_16

extr_list <- extr %>% 
  lapply(FUN = function(x){
    the_tab <- table(x$value)
    props <- the_tab/sum(the_tab)
    cats <- names(the_tab)
    df <- tibble::tibble(cats, props)
  })
names(extr_list) <- cams_sf_buffers_16$camera_id

extr_table <- dplyr::bind_rows(extr_list, .id = "camera_id") %>% 
  dplyr::mutate(props = as.double(props)) %>% 
  dplyr::left_join(lu_dat, by="cats") %>% 
  dplyr::select(camera_id,category_code, props) %>% 
  tidyr::pivot_wider(names_from = "category_code", values_from = "props") %>% 
  as.data.frame()
extr_table[is.na(extr_table)] <- 0

extr_table_sub <- extr_table %>% 
  dplyr::filter(camera_id %in% anns_wide_animals_table$camera_id) %>% 
  dplyr::arrange(camera_id)
extr_table_sub_tb <- extr_table_sub %>% 
  dplyr::select(-camera_id)
rownames(extr_table_sub_tb) <- extr_table_sub$camera_id

# lu_cropped <- raster::crop(lu_16, cams_sf_buffers_16)
# raster::plot(lu_cropped)
```

```{r}
#| label: RDA-presence-absence
#| echo: false

source("scripts/3_ordination.R")

# Ordination
stopifnot(all(rownames(anns_wide_animals_table_tb)==rownames(extr_table_sub_tb)))

pa_rda <- vegan::rda(anns_wide_animals_table_tb ~ .,
                       extr_table_sub_tb)

custom_rda_plot(pa_rda)
```

### Events definition

```{r}
#| label: events
#| echo: false

events_plot_days <- anns_wide_animals_joined_mut %>% 
  # dplyr::mutate(ind = paste(species, sex, age, sep = "_")) %>% 
  dplyr::select(plot_id, species, ymd) %>% 
  dplyr::distinct()

events_plot <- events_plot_days %>% 
  dplyr::group_by(plot_id, species) %>%
  dplyr::summarise(day_count=dplyr::n()) %>% 
  dplyr::ungroup()

events_plot_tb <- events_plot %>% 
  tidyr::pivot_wider(values_from = "day_count", names_from = "species") %>%
  dplyr::arrange(plot_id) %>%
  tibble::column_to_rownames("plot_id")

events_plot_tb[is.na(events_plot_tb)] <- 0
events_plot_tb_filt <- events_plot_tb[,colSums(events_plot_tb)>50]
tmp_col <- ncol(events_plot_tb_filt)

events_plot_tb_filt_with_col <- events_plot_tb_filt %>% 
  tibble::rownames_to_column("plot_id")
```

### RDA based on events

```{r}
#| label: RDA-events
#| echo: false

events_cam_days <- anns_wide_animals_joined_mut %>% 
  dplyr::select(camera_id, species, month, ymd) %>% 
  dplyr::distinct() 

events_cam <- events_cam_days %>% 
  dplyr::group_by(camera_id, species) %>%
  dplyr::summarise(day_count=dplyr::n()) %>% 
  dplyr::ungroup()

events_tb_cam <- events_cam %>% 
  tidyr::pivot_wider(values_from = "day_count", names_from = "species") %>%
  dplyr::arrange(camera_id) %>%
  tibble::column_to_rownames("camera_id")

events_tb_cam[is.na(events_tb_cam)] <- 0
# events_tb_cam_filt <- events_tb_cam[,colSums(events_tb_cam)>50]
# tmp_col <- ncol(events_tb_cam)

events_tb_cam_hell <- vegan::decostand(events_tb_cam, "hellinger")

events_rda <- vegan::rda(events_tb_cam_hell ~ .,
                         extr_table_sub_tb)

# vegan::RsquareAdj(events_rda)
# custom_rda_plot(events_rda, sp_scale = 1.5, scale_x_sp=0.4, scale_y_sp=0.3,
#                 thres_plot = 0.3)
```

### Clustering

```{r}
#| label: cluster-base
#| echo: false

events_gower <- cluster::daisy(events_tb_cam_hell, "gower")
clust <- hclust(events_gower, method = "ward.D2")
# plot(clust)
```

```{r}
#| label: rda-clust
#| echo: false

clust_grp <- cutree(clust, k=5)
custom_rda_plot(events_rda, sp_scale = 1.5, scale_x_sp=0.4, scale_y_sp=0.3,
                thres_plot = 0.3, clust = clust_grp)
```

```{r}
#| label: test-pie
#| echo: false

cams_sf_with_props <- cams_sf_coords %>% 
  sf::st_drop_geometry() %>% 
  dplyr::select(plot_id,X,Y) %>% 
  dplyr::group_by(plot_id) %>% 
  dplyr::mutate(X=mean(X), Y=mean(Y)) %>%
  dplyr::distinct() %>% 
  dplyr::ungroup() %>% 
  dplyr::left_join(events_plot_tb_filt_with_col, by = "plot_id")

# ggplot2::ggplot() +
#   scatterpie::geom_scatterpie(data = cams_sf_with_props,
#                               ggplot2::aes(x=X, y=Y, group=plot_id),
#                               cols=names(cams_sf_with_props)[4:(4+tmp_col-1)]) + 
#   ggplot2::coord_equal() #+ 
#ggplot2::theme(legend.position = "none")
```

```{r}
#| label: map-pies
#| echo: false

base2 <- ggplot2::ggplot() +
  ggplot2::theme_bw()
for (pol in 1:3){
  base2 <- base2 + 
    ggplot2::geom_polygon(data = dplyr::filter(pols, L3 == pol),
                          ggplot2::aes(x=X, y=Y),
                          col = 1, fill = "grey90")
}

base2 +
  ggplot2::coord_equal(xlim = c(-88.5, -84),
                       ylim = c(50, 54)) +
  scatterpie::geom_scatterpie(data = cams_sf_with_props,
                              ggplot2::aes(x=X, y=Y, group=plot_id),
                              cols=names(cams_sf_with_props)[4:(4+tmp_col-1)],
                              sorted_by_radius = TRUE,
                              legend_name = "Species",
                              pie_scale = 1.5) +
  ggplot2::labs(x="Lat", y="Long")
```

```{r}
#| label: map-groups
#| echo: false

grps_df <- data.frame(camera_id = names(clust_grp),
                      grp = as.factor(clust_grp))

cams_sf_clust <- cams_sf_coords %>% 
  # dplyr::filter(camera_id %in% names(clust_grp)) %>% 
  dplyr::left_join(grps_df, by = "camera_id") %>% 
  dplyr::filter(!(is.na(grp)))

base_cut <- base +
  ggplot2::coord_map(xlim = c(-89, -84),
                     ylim = c(50, 54.5))

base_cut +
  ggplot2::geom_point(data = cams_sf_clust, cex = 1, shape=21, col="black",
                      ggplot2::aes(x=X, y=Y, fill=grp), 
                      inherit.aes = FALSE) +
  ggplot2::labs(fill="Group")
```

```{r}
#| label: clust-geo
#| echo: false

# Spatially constrained clust

events_gower_mod <- events_gower
class(events_gower_mod) <- "dist"

tree <- ClustGeo::hclustgeo(events_gower_mod)
# plot(tree)
# rect.hclust(tree ,k = 5, border = c(4,5,3,2,1))
# legend("topright", legend = paste("cluster",1:5), 
#        fill=1:5,bty= "n", border = "white")

dist_geo <- cams_sf_clust %>% 
  dplyr::arrange(camera_id) %>% 
  sf::st_distance() %>% 
  as.dist()

range.alpha <- seq(0,1,0.1)
K <- 5
cr <- ClustGeo::choicealpha(events_gower_mod, dist_geo, range.alpha, 
  K, graph = F)

clust_geo <- ClustGeo::hclustgeo(events_gower_mod,
                                 dist_geo, alpha = 0.2)
clust_geo_grp <- cutree(clust_geo, k=K)

grps_geo_df <- data.frame(camera_id = names(clust_geo_grp),
                          grp = as.factor(clust_geo_grp))

cams_sf_geo_clust <- cams_sf_coords %>% 
  # dplyr::filter(camera_id %in% names(clust_grp)) %>% 
  dplyr::left_join(grps_geo_df, by = "camera_id") %>% 
  dplyr::filter(!(is.na(grp)))

# plot(clust_geo)
```

```{r}
#| label: clust-geo-plot
#| echo: false

base_cut +
  ggplot2::geom_point(data = cams_sf_geo_clust, cex = 1, shape=21, col="black",
                      ggplot2::aes(x=X, y=Y, fill=grp), 
                      inherit.aes = FALSE) +
  ggplot2::labs(fill="Group")
```

```{r}
#| label: rda-clust-geo
#| echo: false

# custom_rda_plot(events_rda, sp_scale = 1.5, clust = clust_geo_grp)
```

### Density contourmaps

```{r}
#| label: join-sf
#| echo: false

# cams_sf_sp <- anns_wide_animals_joined_mut %>% 
#   dplyr::left_join(cams_sf_coords, by = dplyr::join_by(camera_id, plot_id)) %>% 
#   dplyr::filter(species %in% colnames(events[,-1]))

cams_sf_sp <- events_cam_days %>% 
  dplyr::left_join(cams_sf_coords, by = dplyr::join_by(camera_id)) %>% 
  dplyr::filter(species %in% colnames(events_plot_tb_filt_with_col[,-1]))

cams_sf_sp_sum <- cams_sf_sp %>% 
  dplyr::group_by(camera_id, X, Y, geometry, species, month) %>% 
  dplyr::summarise(count=dplyr::n()) %>% 
  dplyr::ungroup() # %>% 
  # dplyr::group_by(camera_id, X, Y, species) %>% 
  # dplyr::mutate(count=count/sum(count)) %>% 
  # dplyr::ungroup() 
# stopifnot(dim(cams_sf_sp)[1]==dim(anns_wide_animals_joined_mut)[1])
```

```{r}
#| label: heatmap
#| echo: false

cams_sf_sp_filt <- cams_sf_sp %>% 
  dplyr::filter(species == "Caribou", month == "Jun")

base_cut +
  ggplot2::geom_density2d_filled(
    data = cams_sf_sp_filt, ggplot2::aes(X, Y),
    binwidth = 0.05, alpha = 0.5)
```

```{r}
#| label: heatmap-facets
#| echo: false

cams_sf_sp_caribou <- cams_sf_sp %>%
  dplyr::filter(species == "Caribou")

base_cut +
  ggplot2::geom_density2d_filled(
    data = cams_sf_sp_caribou, ggplot2::aes(X, Y),
    alpha = 0.5,breaks = c(seq(0.001,1,by=0.1),5, 10, 20, 50,100), n=20) +
  ggplot2::facet_wrap(~month) +
  ggplot2::coord_equal(xlim = c(-89, -84),
                       ylim = c(50, 55)) +
  ggplot2::theme(
    legend.position='none'
  )
```

```{r}
#| label: bubbleplots
#| echo: false

# cams_sf_sp_sum %>%
#   # dplyr::filter(species == "Caribou") %>%
#   ggplot2::ggplot() +
#   ggplot2::geom_point(ggplot2::aes(x=X, y=Y, size=count, col =species)) +
#   ggplot2::facet_wrap(~month) +
#   ggplot2::coord_equal(xlim = c(-89, -84),
#                        ylim = c(50, 55))

for (sp in unique(cams_sf_sp_sum$species)){
  
  dat <- sf::st_as_sf(cams_sf_sp_sum) %>% 
    dplyr::filter(species == sp)
  
  gg <- base_cut +
    ggplot2::geom_point(data = dat, col="black",
                        ggplot2::aes(x=X, y=Y, size = count), 
                        inherit.aes = FALSE) +
    ggplot2::facet_wrap(~month) +
    ggplot2::labs(size="Days \ndetected")
  
  ggplot2::ggsave(gg, filename = paste0("analysis/figures/",sp,"_bplot.png"))
}
```

![alt text](../figures/Caribou_bplot.png "Caribou")
```{r}
#| label: heatmaps
#| echo: false

for (sp in unique(cams_sf_sp_sum$species)){
  
  cams_sf_sp_spe <- cams_sf_sp %>%
    dplyr::filter(species == sp)
  
  gg <- base_cut +
    ggplot2::geom_density2d_filled(
      data = cams_sf_sp_spe, ggplot2::aes(X, Y),
      alpha = 0.5,breaks = c(seq(0.001,1,by=0.1),5, 10, 20, 50,100), n=20) +
    ggplot2::facet_wrap(~month) +
    ggplot2::coord_equal(xlim = c(-89, -84),
                         ylim = c(50, 55)) +
    ggplot2::theme(
      legend.position='none'
    )
  
  ggplot2::ggsave(gg, filename = paste0("analysis/figures/",sp,"_heatmap.png"))
}
```
![alt text](../figures/Caribou_heatmap.png "Caribou")

```{r}
#| label: plot-tests
#| echo: false

# cams_sf_sp_sum %>%
#   dplyr::filter(species == "Caribou") %>%
#   ggplot2::ggplot() +
#   ggplot2::geom_raster(ggplot2::aes(x=X, y=Y, z=count)) +
#   ggplot2::facet_wrap(~month) +
#   ggplot2::coord_equal(xlim = c(-89, -84),
#                        ylim = c(50, 55))
```

## Discussion

### Choice of methods

TBW

### Future plans

TBW

## Conclusion

## Acknowledgements

- Thank the volunteers for help with tagging.

<!-- The following line inserts a page break  -->
<!--
\newpage

## References

The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  
-->

::: {#refs}
:::

\newpage

 ### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r}
#| label: colophon
#| cache: false

# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```

<!-- 
```{r}
# -------------------------------------------------------------------------

# # Create ordered dataframe, and calculate time interval between images.
# x1 <- x %>%
#   # Sometimes VNA sneaks in here
#   mutate(number_individuals = as.numeric(ifelse(number_individuals == "VNA", 1, number_individuals))) %>%
#   # Amalgamate tags of same species in same image; currently broken into two separate rows
#   group_by(location, {{datetime_col}}, common_name) %>%
#   mutate(number_individuals = sum(number_individuals)) %>%
#   distinct(location, {{datetime_col}}, common_name, number_individuals, .keep_all = TRUE) %>%
#   ungroup() %>%
#   # Order the dataframe
#   arrange(project, location, {{datetime_col}}, common_name) %>%
#   group_by(project, location, common_name) %>%
#   # Calculate the time difference between subsequent images
#   mutate(interval = int_length({{datetime_col}} %--% lag({{datetime_col}}))) %>%
#   # Is this considered a new detection?
#   mutate(new_detection = ifelse(is.na(interval) | abs(interval) >= threshold, TRUE, FALSE)) %>%
#   ungroup() %>%
#   # Number independent detections
#   mutate(detection = c(1, cumsum(new_detection[-1]) + 1))
# 
# # Summarise detections
# x2 <- x1 %>%
#   group_by(detection, project, location, common_name, scientific_name) %>%
#   summarise(start_time = min({{datetime_col}}),
#             end_time = max({{datetime_col}}),
#             total_duration_seconds = int_length(start_time %--% end_time),
#             n_images = n(),
#             avg_animals = mean(number_individuals),
#             max_animals = max(number_individuals))
```

```{r}
#| label: ecoregions-ggplot
#| echo: false

# ggplot2::ggplot(zones_filter) +
#   ggplot2::theme_bw() +
#   ggplot2::geom_sf()
```
-->
