---
title: "Ring of Fire Camera Detections Report"
author:
  - Valentin Lucet:
      # correspondence: "yes"
      email: valentin.lucet@gmail.com
      orcid: "0000-0003-0268-818X"
      institute: wlu
  - Frances Stewart:
      institute: wlu
      orcid: "0000-0001-9344-8346"
institute:
  - wlu:
      name: Wilfrid Laurier University
      # address: 23 Science Street, Eureka, Mississippi, USA
title-block-published: "Last updated"  
date: now
date-format: long
format: 
  docx:
    reference-doc: "../templates/template_edited.docx" # Insert path for the DOCX file
execute:
  echo: true
  warning: false
  message: false
  comment: "#>"
  fig-path: "../figures/"
  fig-dpi: 600
filters:
  - ../templates/scholarly-metadata.lua
  - ../templates/author-info-blocks.lua
  - ../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/landscape-ecology.csl" # Insert path for the bib-style
abstract: |
  Abstract TBW
# keywords: |
#   keyword 1; keyword 2; keyword 3
# highlights: |
#   These are the highlights. 
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '~/Documents/WILDLab/rofcamtrap/')
options(scipen = 1, digits = 2)
```

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored.

With the following code you can access and display values from the yml header above.
Keywords: `r rmarkdown::metadata$keywords`
Highlights: `r rmarkdown::metadata$highlights`

Here is a citation [@Marwick2017] -->

<!-- The actual document text starts here: -->

## Summary

TBW

\newpage

## Introduction

- What this report is about
- Recycle the other introductions
- Importance of monitoring
- Data collection challenge
- New methods to the rescue
- Data challenges remain
- AI plan

## Methods

### Sampling protocol

- Recycle the info from proposal

### Image detection

```{r}
#| label: load-data
#| echo: false

if (!file.exists("analysis/data/derived_data/annotations.rds") |
    !file.exists("analysis/data/derived_data/annotations_wide.rds")){
  source("scripts/1_preprocess_annotations.R")
} else {
  anns <- readRDS("analysis/data/derived_data/annotations.rds")
  anns_wide <- readRDS("analysis/data/derived_data/annotations_wide.rds")
}

if (!file.exists("analysis/data/derived_data/detections.rds")){
  source("scripts/2_preprocess_detections.R")
} else {
  dets <- readRDS("analysis/data/derived_data/detections.rds")
}

# Compute total amount of images
nb_image <- length(unique(dets$image_id))
nb_image_fmt <- prettyNum(nb_image, big.mark = ",")

# Hardcoded check
stopifnot(nb_image == 2788375)
```

Images were retrieved from all cameras using a SD card reader and copied onto a 10 TB hard drive of brand LaCie. The images amounted to 1.8TB of memory on disk, for a total of __`r nb_image_fmt`__ images. Images were stored with the following directory structure:

- Plot id (e.g. P128)
- Site id (e.g. P128-1)
- Camera id (e.g. CFS-10)
- DCIM folder (created by the camera)
- Overflow folder (e.g. 100RECNX, each such folder contains up to 10,000 images)

The images were processed through the animal detection model MegaDetector, version 5.0, using a Lenovo X1 laptop with a NVIDIA GeForce GTX 1650 Max-Q graphics card, which took about 2 weeks of quasi-continuous processing to complete. The model processes each image and produces “detections” (bounding boxes) at a  variable confidence score.

```{r}
#| label: basics-stats-1
#| echo: false

# Select and distinct down to image-based infos
dets_images <- dets |>  dplyr::select(image_id, max_confidence, isempty) |> 
  dplyr::distinct()

# Breakdown of which images triggered a MD detection
dets_tb <- dets_images$isempty |> table()
dets_tb_sum <- sum(dets_tb)
dets_tb_percent <- dets_tb/dets_tb_sum*100

dets_tb_fmt <- prettyNum(dets_tb, big.mark = ",")

# Check total number of images
stopifnot(dets_tb_sum == length(unique(dets$image_id)))
```

About __`r dets_tb_percent[1]` %__ of the images, or __`r dets_tb_fmt[1]`__ images, were found by the model to possibly have either a person, animal, or vehicle. The model did not produce detections for __`r dets_tb_fmt[2]`__ images, or __`r dets_tb_percent[2]` %__ of the total.

```{r}
#| label: basics-stats-2
#| echo: false
dets_0 <- dets |> dplyr::filter(confidence > 0)
dets_0.1 <- dets |> dplyr::filter(confidence > 0.1)

# Breakdown of detections by categories (animal, person, vehicles)
dets_tb_cat_unfil <- dets_0 |> dplyr::pull(category_id) |> table()
dets_tb_cat_unfil_sum <- sum(dets_tb_cat_unfil)
dets_tb_cat_unfil_percent <- dets_tb_cat_unfil/dets_tb_cat_unfil_sum*100

dets_tb_cat_unfil_fmt <- prettyNum(dets_tb_cat_unfil, big.mark = ",")
dets_tb_cat_unfil_sum_fmt <- prettyNum(dets_tb_cat_unfil_sum, big.mark = ",")

# Breakdown of detections above 0.1 by categories (animal, persons, vehicles)
dets_tb_cat <- dets_0.1 |> dplyr::pull(category_id) |> table()
dets_tb_cat_sum <- sum(dets_tb_cat)
dets_tb_cat_percent <- dets_tb_cat/sum(dets_tb_cat)*100

dets_tb_cat_fmt <- prettyNum(dets_tb_cat, big.mark = ",")
dets_tb_cat_sum_fmt <- prettyNum(dets_tb_cat_sum, big.mark = ",")
```

This resulted in a total of __`r dets_tb_cat_unfil_sum_fmt`__ detections. The totals for each category are: __`r dets_tb_cat_unfil_fmt[1]`__ animals (or __`r dets_tb_cat_unfil_percent[1]` %__); __`r dets_tb_cat_unfil_fmt[2]`__ persons (or __`r dets_tb_cat_unfil_percent[2]` %__); and __`r dets_tb_cat_unfil_fmt[3]`__ vehicles (or __`r dets_tb_cat_unfil_percent[3]` %__).

Using a cut-off value for confidence threshold of 0.1, this left us with a total of __`r dets_tb_cat_sum_fmt`__ detections to sort through (see @fig-detections-histogram for an histogram of the detection scores, grouped by detection types). The totals for each category are: __`r dets_tb_cat_fmt[1]`__ animals (or __`r dets_tb_cat_percent[1]` %__); __`r dets_tb_cat_fmt[2]`__ persons (or __`r dets_tb_cat_percent[2]` %__); and __`r dets_tb_cat_fmt[3]`__ vehicles (or __`r dets_tb_cat_percent[3]` %__). 

```{r}
#| label: fig-detections-histogram
#| echo: false
#| fig-cap: "Histogram of detection confidence scores."

# Histogram of confidence scores above 0.1
dets_0.1 |> 
  dplyr::mutate(category_id = as.character(category_id)) |> 
  dplyr::mutate(Type = dplyr::case_match(category_id,
                                         "0" ~ "Empty",
                                         "1" ~ "Animal",
                                         "2" ~ "Person",
                                         "3" ~ "Vehicle")) |> 
  ggplot2::ggplot() +
  ggplot2::theme_bw() +
  ggplot2::geom_histogram(ggplot2::aes(x=confidence, group=Type, fill=Type),
                          bins = 100) +
  ggplot2::scale_fill_viridis_d() +
  ggplot2::xlab("Confidence Score") +
  ggplot2::ylab("Count")
```

- Add explanation about image bursts and upload of bursts including empties

### Tagging platform selection

We had in mind the following criteria when selecting the proper tool to tag our images and bounding boxes:

- *Deployable online*. This was to allow for for multiple taggers
- *Flexible tagging interface*. Few platforms allow for a full customization of the tagging interface, down to the smallest details.
- *Allowing to tag multiple bounding boxes per image*. Most platforms only allow for tagging the entire image, and not for portions of it (e.g. bounding boxes of detections produced by MegaDetector). This is necessary for when we will crop our images to train our neural network model. 
- *Optionally, open source,* to allow for maximum reproducibility of the process. 

We looked at platforms not traditionally used for tagging camera trap images, but used by the larger community of machine learning practitioners for which the task of tagging is a common step, known as labeling. We found two platforms that matched all those criteria: LabelStudio and CVAT. After testing both platforms, LabelStudio was chosen as it was simpler to implement. The Community edition of LabelStudio was deployed on an Ubuntu virtual machine hosted by Compute Canada, using an Apache server and a NGINX reverse proxy, which is a standard approach for custom hosting of websites.

### Tagging progress

```{r}
#| label: basics-stats-3
#| echo: false

# Number of uploaded images
uploaded <- dets |> dplyr::filter(confidence > 0.1) |> dplyr::pull(image_id) |> 
  unique() |> length()

uploaded_fmt <- prettyNum(uploaded, big.mark = ",")

# Number of images viewed
viewed <- length(unique(anns_wide$image_id))
viewed_fmt <- prettyNum(viewed, big.mark = ",")

# Percentage of image viewed (in the total)
viewed_pct <- viewed/length(unique(dets$image_id))*100

# Percentage of image viewed from what was uploaded to the platform
viewed_pct_up <- length(unique(anns_wide$image_id))/uploaded*100

# Filter for non empty images
anns_wide_noempty <- anns_wide |>
  dplyr::filter(!is.na(to_name))

# Number of processed annotations
processed <- nrow(anns_wide_noempty)
processed_fmt <- prettyNum(processed, big.mark = ",")

# Percentage of animal annotations processed
processed_pct <- processed/dets_tb_cat[1]*100

# Number of nonempty images viewed
processed_img <- length(unique(anns_wide_noempty$image_id))
processed_img_fmt <- prettyNum(processed_img, big.mark = ",")

# Percentage of nonempty images viewed (in the total)
processed_img_pct <- processed_img/length(unique(dets$image_id))*100

# Percentage of nonempty images viewed (in the detected images > 0.1)
processed_img_up_pct <- processed_img/uploaded*100
```

Out of the __`r dets_tb_cat_fmt[1]`__ animal detections, __`r processed_fmt`__ have been processed on the platform (or __`r processed_pct` %__) for a total of __`r processed_img_fmt`__ images (i.e. __`r processed_img_pct` %__ of the total amount of images, or __`r processed_img_up_pct` %__ of the total amount of images uploaded to the platform). This does not include the empty images also viewed as part of a set, bringing that amount to 92,826 “detections” and __`r viewed_fmt`__, (i.e. __`r viewed_pct` %__ of the total amount of images, or __`r viewed_pct_up` %__ of the total amount of images uploaded to the platform).

```{r}
#| label: mans
#| echo: false

# Deleted predictions
dels <- anns_wide_noempty |> dplyr::filter(is.na(species))
dels_nb <- nrow(dels)
dels_nb_fmt <- prettyNum(dels_nb, big.mark = ",")
dels_nb_pct <- dels_nb/nrow(anns_wide_noempty)*100

# Should be no manuals here
stopifnot((anns_wide_noempty |> dplyr::filter(is.na(species)) 
           |> dplyr::filter(manual)) == 0)

# Actual annotations
true_anns <- anns_wide_noempty |> dplyr::filter(!is.na(species))
true_anns_nb <- nrow(true_anns)
# true_anns_nb_fmt <- prettyNum(true_anns_nb, big.mark = ",")
# true_anns_nb_pct <- true_anns_nb/processed*100

# Non manuals 
non_mans <- anns_wide_noempty |> dplyr::filter(!is.na(species)) |> 
  dplyr::filter(!manual)
non_mans_nb <- nrow(non_mans)
non_mans_nb_fmt <- prettyNum(non_mans_nb, big.mark = ",")
non_mans_nb_pct <- non_mans_nb/nrow(anns_wide_noempty)*100

# Mans
mans <- anns_wide_noempty |> dplyr::filter(!is.na(species)) |> 
  dplyr::filter(manual)
mans_nb <- nrow(mans)
mans_nb_fmt <- prettyNum(mans_nb, big.mark = ",")
mans_nb_pct <- mans_nb/nrow(anns_wide_noempty)*100

# adjusted
orig_tb <- anns_wide_noempty$origin |> table()
orig_tb_pct <- orig_tb/sum(orig_tb)*100
orig_tb_fmt <- prettyNum(orig_tb, big.mark = ",")
```

Out of the __`r processed_fmt`__ detections, __`r dels_nb_fmt`__ were false positives (or __`r dels_nb_pct` %__), and __`r non_mans_nb_fmt`__ were true positives (or __`r non_mans_nb_pct` %__), to which __`r mans_nb_fmt`__ false negatives were added (manually added bounding boxes, __`r mans_nb_pct` %__). Out of the __`r non_mans_nb_fmt`__ true positives, __`r orig_tb_fmt[3]`__ had to have their bounding box adjusted,

### Issues encountered

```{r}
#| label: quality-control
#| eval: false
#| echo: false

# Only annotations for animals
anns_wide_animals <- anns_wide_noempty %>% 
  filter(species != 'Human') %>% 
  filter(species != 'Vehicle')

# Unknowns and bird breakdown
anns_wide_animals %>% filter(species == "Unknown") %>% pull(id) %>% 
  str_sub(1,4) %>% table() %>% sort()
anns_wide_animals %>% filter(str_detect(species,"Bird")) %>% pull(id) %>% 
  str_sub(1,4) %>% table() %>% sort()

# Join
anns_wide_animals_joined <- anns_wide_animals %>% 
  right_join(info_images, by = "image_id")
```

- Issues with vegetation falsely detected.

## Preliminary results

### Species ID summary

TBW

```{r}
#| label: species
#| eval: false

# Summary by species

anns_wide_animals_table <- anns_wide_animals %>% 
  mutate(camera_id = anns_wide_animals$id %>% str_split("_") %>% 
           map(~.x[[2]]) %>% unlist()) %>% 
  dplyr::select(camera_id, species) %>% 
  filter(species != "Unknown") %>%
  table() %>% 
  `>`(0) %>% 
  `+`(0) %>% 
  as.data.frame() %>% 
  rownames_to_column("camera_id") %>% 
  arrange(camera_id)
anns_wide_animals_table_tb <- anns_wide_animals_table %>% 
  dplyr::select(-camera_id)
rownames(anns_wide_animals_table_tb) <- anns_wide_animals_table$camera_id

```

### Ordination

TBW

```{r}
#| label: spatial
#| eval: false

RoF_CameraDeploymentLog_WLU <- 
  read_excel("data/raw/WLU_Cameras_Log_2023.xlsx") %>% 
  janitor::clean_names()  

RoF_CameraDeploymentLog_WLU_old <- 
  read_excel("data/raw/RoF_CameraDeploymentLog_WLU.xlsx",
             sheet = "Sheet1") %>% 
  janitor::clean_names()  

cams_sf <- RoF_CameraDeploymentLog_WLU %>% 
  filter(!is.na(latitude)) %>% 
  filter(!is.na(longitude)) %>% 
  st_as_sf(coords=c("longitude","latitude"), crs="EPSG:4326")
plot(cams_sf$geometry)

lu <- raster("data/raw/CAN_LC_2015_CAL.tif")

lu_dat <- read_csv("data/raw/lu.txt") %>% 
  mutate(cats = as.factor(code))

cams_sf_buffers <- cams_sf %>% 
  st_transform(st_crs(lu)) %>% 
  st_buffer(dist = 1000)

extr <- exact_extract(lu, cams_sf_buffers)

extr_list <- extr %>% 
  lapply(FUN = function(x){
    the_tab <- table(x$value)
    props <- the_tab/sum(the_tab)
    cats <- names(the_tab)
    df <- tibble(cats, props)
  })
names(extr_list) <- cams_sf_buffers$camera_id
extr_table <- bind_rows(extr_list, .id = "camera_id") %>% 
  mutate(props = as.double(props)) %>% 
  left_join(lu_dat, by="cats") %>% 
  dplyr::select(camera_id,category_code, props) %>% 
  # mutate(cats = paste0("cat_", cats)) %>% 
  pivot_wider(names_from = "category_code", values_from = "props") %>% 
  as.data.frame()
extr_table[is.na(extr_table)] <- 0

extr_table_sub <- extr_table %>% 
  filter(camera_id %in% anns_wide_animals_table$camera_id) %>% 
  arrange(camera_id)
extr_table_sub_tb <- extr_table_sub %>% 
  dplyr::select(-camera_id)
rownames(extr_table_sub_tb) <- extr_table_sub$camera_id

# -------------------------------------------------------------------------

# Ordination
all(rownames(anns_wide_animals_table_tb)==rownames(extr_table_sub_tb))
# plot(rda(anns_wide_animals_table_tb,extr_table_sub_tb))

test_rda <- rda(anns_wide_animals_table_tb ~ .,
                extr_table_sub_tb)

sp_scores <- scores(test_rda,
                    choices = 1:2,
                    display = "sp"
)

plot(test_rda,
     display = c("sp", "lc", "cn")
)
```

## Discussion

### Choice of methods

TBW

### Future plans

TBW

## Conclusion

## Acknowledgements

- Thank the volunteers for help with tagging

<!-- The following line inserts a page break  -->

\newpage

## References

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

::: {#refs}
:::

\newpage

<!-- ### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r}
#| label: colophon
#| cache: false

# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```
-->
